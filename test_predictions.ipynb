{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prediction-demo",
   "metadata": {},
   "source": [
    "# Pneumonia Detection - Model Prediction Testing\n",
    "\n",
    "This notebook demonstrates how to test your trained model on new chest X-ray images to verify its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-model",
   "metadata": {},
   "source": [
    "## Load Your Trained Model\n",
    "\n",
    "Make sure you have your best trained model file (.h5) in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-best-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available model files\n",
    "model_files = [f for f in os.listdir('.') if f.endswith('.h5')]\n",
    "print(\"Available model files:\")\n",
    "for i, file in enumerate(model_files):\n",
    "    print(f\"{i+1}. {file}\")\n",
    "\n",
    "# Load the best model (change filename if needed)\n",
    "if model_files:\n",
    "    model_path = model_files[0]  # Use first available model\n",
    "    print(f\"\\nðŸ”„ Loading model: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        print(f\"âœ… Model loaded successfully!\")\n",
    "        print(f\"ðŸ“Š Model architecture: {model.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {e}\")\n",
    "else:\n",
    "    print(\"âŒ No model files found! Please train a model first using pneumonia.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-setup",
   "metadata": {},
   "source": [
    "## Setup Test Data Generator\n",
    "\n",
    "Let's create a data generator to load test images systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-test-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Try to find test directory\n",
    "test_dirs = ['./DATASET/chest_xray_balanced/test', './DATASET/chest_xray/test']\n",
    "test_dir = None\n",
    "\n",
    "for dir_path in test_dirs:\n",
    "    if os.path.exists(dir_path):\n",
    "        test_dir = dir_path\n",
    "        print(f\"âœ… Found test directory: {test_dir}\")\n",
    "        break\n",
    "\n",
    "if test_dir:\n",
    "    # Create test generator\n",
    "    test_gen = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False  # Keep order for proper comparison\n",
    "    )\n",
    "    \n",
    "    print(f\"ðŸ“Š Test generator created with {test_gen.samples} samples\")\n",
    "    print(f\"ðŸ·ï¸ Class indices: {test_gen.class_indices}\")\n",
    "else:\n",
    "    print(\"âŒ Test directory not found! Please extract DATASET.zip first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-prediction",
   "metadata": {},
   "source": [
    "## Test Single Image Prediction\n",
    "\n",
    "Let's test the model on individual images to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, image_path, show_image=True):\n",
    "    \"\"\"\n",
    "    Predict pneumonia for a single image and display results\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction_prob = model.predict(img_array, verbose=0)[0][0]\n",
    "    \n",
    "    # Determine class and confidence\n",
    "    if prediction_prob > 0.5:\n",
    "        predicted_class = 'PNEUMONIA'\n",
    "        confidence = prediction_prob\n",
    "    else:\n",
    "        predicted_class = 'NORMAL'\n",
    "        confidence = 1 - prediction_prob\n",
    "    \n",
    "    # Get actual class from path\n",
    "    actual_class = 'PNEUMONIA' if 'PNEUMONIA' in image_path.upper() else 'NORMAL'\n",
    "    is_correct = predicted_class == actual_class\n",
    "    \n",
    "    # Display results\n",
    "    if show_image:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Show image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Chest X-ray\\n{os.path.basename(image_path)}')\n",
    "        \n",
    "        # Show prediction results\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Create text summary\n",
    "        result_text = f\"\"\"\n",
    "PREDICTION RESULTS\n",
    "\n",
    "ðŸ”® Predicted: {predicted_class}\n",
    "âœ… Actual: {actual_class}\n",
    "ðŸ“Š Confidence: {confidence:.1%}\n",
    "ðŸ“ˆ Raw Score: {prediction_prob:.4f}\n",
    "\n",
    "{'âœ… CORRECT' if is_correct else 'âŒ INCORRECT'}\n",
    "\n",
    "Model Logic:\n",
    "â€¢ Score > 0.5 = PNEUMONIA\n",
    "â€¢ Score â‰¤ 0.5 = NORMAL\n",
    "\"\"\"\n",
    "        \n",
    "        plt.text(0.1, 0.5, result_text, fontsize=11, \n",
    "                verticalalignment='center',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", \n",
    "                         facecolor='lightgreen' if is_correct else 'lightcoral',\n",
    "                         alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nðŸ“‹ {os.path.basename(image_path)}\")\n",
    "    print(f\"ðŸ”® Predicted: {predicted_class} ({confidence:.1%})\")\n",
    "    print(f\"âœ… Actual: {actual_class}\")\n",
    "    print(f\"{'âœ… CORRECT' if is_correct else 'âŒ INCORRECT'} - Raw score: {prediction_prob:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'image_path': image_path,\n",
    "        'predicted_class': predicted_class,\n",
    "        'actual_class': actual_class,\n",
    "        'confidence': confidence,\n",
    "        'raw_probability': prediction_prob,\n",
    "        'is_correct': is_correct\n",
    "    }\n",
    "\n",
    "print(\"âœ… Single image prediction function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-random-samples",
   "metadata": {},
   "source": [
    "## Test Random Sample Images\n",
    "\n",
    "Let's test the model on random images from the test set to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-random-images",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_dir and os.path.exists(test_dir):\n",
    "    # Get all test image paths\n",
    "    all_test_images = []\n",
    "    for root, dirs, files in os.walk(test_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                all_test_images.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"ðŸ“Š Found {len(all_test_images)} test images\")\n",
    "    \n",
    "    # Test on random sample\n",
    "    num_samples = 5  # Change this number to test more/fewer images\n",
    "    sample_images = random.sample(all_test_images, min(num_samples, len(all_test_images)))\n",
    "    \n",
    "    print(f\"\\nðŸ” Testing on {len(sample_images)} random images...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    for i, img_path in enumerate(sample_images, 1):\n",
    "        print(f\"\\n[{i}/{len(sample_images)}] Testing: {os.path.basename(img_path)}\")\n",
    "        result = predict_single_image(model, img_path, show_image=True)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Summary\n",
    "    correct_count = sum(1 for r in results if r['is_correct'])\n",
    "    accuracy = correct_count / len(results)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š SAMPLE TEST RESULTS:\")\n",
    "    print(f\"Total tested: {len(results)}\")\n",
    "    print(f\"Correct: {correct_count}\")\n",
    "    print(f\"Incorrect: {len(results) - correct_count}\")\n",
    "    print(f\"Sample Accuracy: {accuracy:.1%}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Cannot run test - dataset not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-evaluation",
   "metadata": {},
   "source": [
    "## Full Test Set Evaluation\n",
    "\n",
    "Let's evaluate the model on the entire test set for comprehensive performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test_gen' in locals():\n",
    "    print(\"ðŸ”„ Evaluating model on full test set...\")\n",
    "    \n",
    "    # Reset generator\n",
    "    test_gen.reset()\n",
    "    \n",
    "    # Get predictions for all test images\n",
    "    predictions = model.predict(test_gen, verbose=1)\n",
    "    predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "    true_classes = test_gen.classes\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    print(f\"\\nðŸ“Š FULL TEST SET RESULTS:\")\n",
    "    print(f\"Total images: {len(true_classes)}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['NORMAL', 'PNEUMONIA'],\n",
    "                yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "    plt.title(f'Confusion Matrix\\nTest Accuracy: {accuracy:.1%}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(true_classes, predicted_classes, \n",
    "                                 target_names=['NORMAL', 'PNEUMONIA'])\n",
    "    print(f\"\\nðŸ“ˆ DETAILED CLASSIFICATION REPORT:\")\n",
    "    print(report)\n",
    "    \n",
    "    # Class-wise accuracy\n",
    "    normal_mask = true_classes == 0\n",
    "    pneumonia_mask = true_classes == 1\n",
    "    \n",
    "    normal_accuracy = np.mean(predicted_classes[normal_mask] == true_classes[normal_mask])\n",
    "    pneumonia_accuracy = np.mean(predicted_classes[pneumonia_mask] == true_classes[pneumonia_mask])\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ CLASS-WISE PERFORMANCE:\")\n",
    "    print(f\"NORMAL accuracy: {normal_accuracy:.1%} ({np.sum(normal_mask)} images)\")\n",
    "    print(f\"PNEUMONIA accuracy: {pneumonia_accuracy:.1%} ({np.sum(pneumonia_mask)} images)\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Cannot run full evaluation - test generator not available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction-examples",
   "metadata": {},
   "source": [
    "## Show Prediction Examples\n",
    "\n",
    "Let's look at some specific examples of correct and incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'all_test_images' in locals():\n",
    "    # Find some correct and incorrect predictions\n",
    "    print(\"ðŸ” Finding examples of correct and incorrect predictions...\")\n",
    "    \n",
    "    correct_normal = []\n",
    "    correct_pneumonia = []\n",
    "    incorrect_predictions = []\n",
    "    \n",
    "    # Test a larger sample to find examples\n",
    "    sample_for_examples = random.sample(all_test_images, min(20, len(all_test_images)))\n",
    "    \n",
    "    for img_path in sample_for_examples:\n",
    "        result = predict_single_image(model, img_path, show_image=False)\n",
    "        \n",
    "        if result['is_correct']:\n",
    "            if result['actual_class'] == 'NORMAL':\n",
    "                correct_normal.append((img_path, result))\n",
    "            else:\n",
    "                correct_pneumonia.append((img_path, result))\n",
    "        else:\n",
    "            incorrect_predictions.append((img_path, result))\n",
    "    \n",
    "    # Show examples\n",
    "    print(f\"\\nâœ… Found {len(correct_normal)} correct NORMAL predictions\")\n",
    "    print(f\"âœ… Found {len(correct_pneumonia)} correct PNEUMONIA predictions\")\n",
    "    print(f\"âŒ Found {len(incorrect_predictions)} incorrect predictions\")\n",
    "    \n",
    "    # Display one example from each category if available\n",
    "    if correct_normal:\n",
    "        print(\"\\nðŸ“¸ Example: Correctly identified NORMAL case\")\n",
    "        predict_single_image(model, correct_normal[0][0], show_image=True)\n",
    "    \n",
    "    if correct_pneumonia:\n",
    "        print(\"\\nðŸ“¸ Example: Correctly identified PNEUMONIA case\")\n",
    "        predict_single_image(model, correct_pneumonia[0][0], show_image=True)\n",
    "    \n",
    "    if incorrect_predictions:\n",
    "        print(\"\\nðŸ“¸ Example: Incorrect prediction (for analysis)\")\n",
    "        predict_single_image(model, incorrect_predictions[0][0], show_image=True)\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Cannot show examples - test images not loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-test",
   "metadata": {},
   "source": [
    "## Test Your Own Image\n",
    "\n",
    "You can test the model on your own chest X-ray image by providing the path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-image-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your own image\n",
    "# Replace 'your_image_path.jpg' with the actual path to your image\n",
    "custom_image_path = 'your_image_path.jpg'  # Change this path\n",
    "\n",
    "if os.path.exists(custom_image_path):\n",
    "    print(f\"ðŸ” Testing custom image: {custom_image_path}\")\n",
    "    result = predict_single_image(model, custom_image_path, show_image=True)\n",
    "else:\n",
    "    print(\"ðŸ’¡ To test your own image:\")\n",
    "    print(\"1. Upload your chest X-ray image to this directory\")\n",
    "    print(\"2. Change 'custom_image_path' above to your image filename\")\n",
    "    print(\"3. Run this cell again\")\n",
    "    \n",
    "    # Show available image files\n",
    "    image_files = [f for f in os.listdir('.') if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if image_files:\n",
    "        print(\"\\nAvailable image files in current directory:\")\n",
    "        for img in image_files:\n",
    "            print(f\"  - {img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "1. **Load your trained model** and test it on new images\n",
    "2. **Make predictions** on individual chest X-ray images\n",
    "3. **Evaluate model performance** on the test dataset\n",
    "4. **Visualize results** with confusion matrices and examples\n",
    "5. **Analyze correct and incorrect predictions** to understand model behavior\n",
    "\n",
    "### Key Points:\n",
    "- The model outputs a probability score between 0 and 1\n",
    "- Score > 0.5 = PNEUMONIA, Score â‰¤ 0.5 = NORMAL\n",
    "- Higher confidence scores indicate more certain predictions\n",
    "- Always validate predictions with medical professionals in real applications\n",
    "\n",
    "### Next Steps:\n",
    "- Test the model on more diverse datasets\n",
    "- Analyze failure cases to improve the model\n",
    "- Consider ensemble methods for better performance\n",
    "- Implement Grad-CAM for visual explanations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}